{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append('../..')\n",
    "from src.utils import load_env_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {DEVICE} for inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed : int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR, _, _ = load_env_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_path = os.path.join(DATA_DIR, 'isic_2024/train-metadata.csv')\n",
    "test_meta_path = os.path.join(DATA_DIR, 'isic_2024/test-metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(train_meta_path)\n",
    "test_metadata = pd.read_csv(test_meta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the categorical & numerical columns\n",
    "categorical_cols = test_metadata.select_dtypes(include=[object]).columns.tolist()\n",
    "numerical_cols = test_metadata.select_dtypes(include=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col, target_col, group_col = 'isic_id', 'target', 'patient_id'\n",
    "\n",
    "irrelevant_cols = ['isic_id', 'patient_id', 'image_type', 'copyright_license', 'target']\n",
    "\n",
    "# Filter out irrelevant columns\n",
    "cat_features = [col for col in categorical_cols if col not in irrelevant_cols] + ['combined_anatomical_site']\n",
    "num_features = [col for col in numerical_cols if col not in irrelevant_cols]\n",
    "\n",
    "# Train columns\n",
    "train_cols = cat_features + num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(metadata: pd.DataFrame):\n",
    "    columns = []\n",
    "    df = pl.DataFrame(metadata)\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col('tbp_lv_minorAxisMM').truediv(pl.col('clin_size_long_diam_mm'))\n",
    "        .cast(pl.Float32).alias('lesion_size_ratio'),\n",
    "\n",
    "        pl.col('tbp_lv_areaMM2').truediv(pl.col('tbp_lv_perimeterMM').pow(2))\n",
    "        .cast(pl.Float32).alias('lesion_shape_index'),\n",
    "\n",
    "        pl.col('tbp_lv_H').sub(pl.col('tbp_lv_Hext')).abs()\n",
    "        .cast(pl.Float32).alias('hue_contrast'),\n",
    "\n",
    "        pl.col('tbp_lv_L').sub(pl.col('tbp_lv_Lext')).abs()\n",
    "        .cast(pl.Float32).alias('luminance_contrast'),\n",
    "\n",
    "        pl.col('tbp_lv_deltaA').pow(2).add(pl.col('tbp_lv_deltaB').pow(2)).add(pl.col('tbp_lv_deltaL').pow(2)).sqrt()\n",
    "        .cast(pl.Float32).alias('lesion_color_difference'),\n",
    "\n",
    "        pl.col('tbp_lv_norm_border').add(pl.col('tbp_lv_symm_2axis'))\n",
    "        .cast(pl.Float32).alias('border_complexity'),\n",
    "\n",
    "        pl.col('tbp_lv_color_std_mean').truediv(pl.col('tbp_lv_radial_color_std_max'))\n",
    "        .cast(pl.Float32).alias('color_uniformity'),\n",
    "    ])\n",
    "    columns += ['lesion_size_ratio', 'lesion_shape_index', 'hue_contrast', 'luminance_contrast', 'lesion_color_difference', 'border_complexity', 'color_uniformity']\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col('tbp_lv_x').pow(2).add(pl.col('tbp_lv_y').pow(2)).add(pl.col('tbp_lv_z').pow(2)).sqrt()\n",
    "        .cast(pl.Float32).alias('position_distance_3d'),\n",
    "\n",
    "        pl.col('tbp_lv_perimeterMM').truediv(pl.col('tbp_lv_areaMM2'))\n",
    "        .cast(pl.Float32).alias('perimeter_to_area_ratio'),\n",
    "\n",
    "        pl.col('tbp_lv_areaMM2').truediv(pl.col('tbp_lv_perimeterMM'))\n",
    "        .cast(pl.Float32).alias('area_to_perimeter_ratio'),\n",
    "\n",
    "        pl.col('tbp_lv_deltaLBnorm').add(pl.col('tbp_lv_norm_color'))\n",
    "        .cast(pl.Float32).alias('lesion_visibility_score'),\n",
    "\n",
    "        pl.col('anatom_site_general').add('_').add(pl.col('tbp_lv_location'))\n",
    "        .cast(pl.Categorical).alias('combined_anatomical_site'),\n",
    "\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_norm_border'))\n",
    "        .cast(pl.Float32).alias('symmetry_border_consistency'),\n",
    "\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_norm_border')).truediv(pl.col('tbp_lv_symm_2axis').add(pl.col('tbp_lv_norm_border')))\n",
    "        .cast(pl.Float32).alias('consistency_symmetry_border'),\n",
    "    ])\n",
    "    columns += ['position_distance_3d', 'perimeter_to_area_ratio', 'area_to_perimeter_ratio', 'lesion_visibility_score', 'symmetry_border_consistency', 'consistency_symmetry_border']\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col('tbp_lv_stdL').truediv(pl.col('tbp_lv_Lext'))\n",
    "        .cast(pl.Float32).alias('color_consistency'),\n",
    "\n",
    "        pl.col('tbp_lv_stdL').mul(pl.col('tbp_lv_Lext')).truediv(pl.col('tbp_lv_stdL').add(pl.col('tbp_lv_Lext')))\n",
    "        .cast(pl.Float32).alias('consistency_color'),\n",
    "\n",
    "        pl.col('clin_size_long_diam_mm').mul(pl.col('age_approx'))\n",
    "        .cast(pl.Float32).alias('size_age_interaction'),\n",
    "\n",
    "        pl.col('tbp_lv_H').mul(pl.col('tbp_lv_color_std_mean'))\n",
    "        .cast(pl.Float32).alias('hue_color_std_interaction'),\n",
    "\n",
    "        pl.col('tbp_lv_norm_border').add(pl.col('tbp_lv_norm_color')).add(pl.col('tbp_lv_eccentricity')).truediv(3)\n",
    "        .cast(pl.Float32).alias('lesion_severity_index'),\n",
    "\n",
    "        pl.col('border_complexity').add(pl.col('lesion_shape_index'))\n",
    "        .cast(pl.Float32).alias('shape_complexity_index'),\n",
    "\n",
    "        pl.col('tbp_lv_deltaA').add(pl.col('tbp_lv_deltaB')).add(pl.col('tbp_lv_deltaL')).add(pl.col('tbp_lv_deltaLBnorm'))\n",
    "        .cast(pl.Float32).alias('color_contrast_index'),\n",
    "    ])\n",
    "    columns += ['color_consistency', 'consistency_color', 'size_age_interaction', 'hue_color_std_interaction', 'lesion_severity_index', 'shape_complexity_index', 'color_contrast_index']\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col('tbp_lv_areaMM2').log1p()\n",
    "        .cast(pl.Float32).alias('log_lesion_area'),\n",
    "\n",
    "        pl.col('clin_size_long_diam_mm').truediv(pl.col('age_approx'))\n",
    "        .cast(pl.Float32).alias('normalized_lesion_size'),\n",
    "\n",
    "        pl.col('tbp_lv_H').add(pl.col('tbp_lv_Hext')).truediv(2)\n",
    "        .cast(pl.Float32).alias('mean_hue_difference'),\n",
    "\n",
    "        pl.col('tbp_lv_deltaA').pow(2).add(pl.col('tbp_lv_deltaB').pow(2)).add(pl.col('tbp_lv_deltaL').pow(2)).truediv(3).sqrt()\n",
    "        .cast(pl.Float32).alias('std_dev_contrast'),\n",
    "\n",
    "        pl.col('tbp_lv_color_std_mean').add(pl.col('tbp_lv_area_perim_ratio')).add(pl.col('tbp_lv_symm_2axis')).truediv(3)\n",
    "        .cast(pl.Float32).alias('color_shape_composite_index'),\n",
    "\n",
    "        pl.arctan2(pl.col('tbp_lv_x'), \n",
    "                   \n",
    "        pl.col('tbp_lv_y'))\n",
    "        .cast(pl.Float32).alias('lesion_orientation_3d'),\n",
    "\n",
    "        pl.col('tbp_lv_deltaA').add(pl.col('tbp_lv_deltaB')).add(pl.col('tbp_lv_deltaL')).truediv(3)\n",
    "        .cast(pl.Float32).alias('overall_color_difference'),\n",
    "    ])\n",
    "    columns += ['log_lesion_area', 'normalized_lesion_size', 'mean_hue_difference', 'std_dev_contrast', 'color_shape_composite_index', 'lesion_orientation_3d', 'overall_color_difference']\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_perimeterMM'))\n",
    "        .cast(pl.Float32).alias('symmetry_perimeter_interaction'),\n",
    "\n",
    "        pl.col('tbp_lv_area_perim_ratio').add(pl.col('tbp_lv_eccentricity')).add(pl.col('tbp_lv_norm_color')).add(pl.col('tbp_lv_symm_2axis')).truediv(4)\n",
    "        .cast(pl.Float32).alias('comprehensive_lesion_index'),\n",
    "\n",
    "        pl.col('tbp_lv_color_std_mean').truediv(pl.col('tbp_lv_stdLExt'))\n",
    "        .cast(pl.Float32).alias('color_variance_ratio'),\n",
    "\n",
    "        pl.col('tbp_lv_norm_border').mul(pl.col('tbp_lv_norm_color'))\n",
    "        .cast(pl.Float32).alias('border_color_interaction'),\n",
    "\n",
    "        pl.col('tbp_lv_norm_border').mul(pl.col('tbp_lv_norm_color')).truediv(pl.col('tbp_lv_norm_border').add(pl.col('tbp_lv_norm_color')))\n",
    "        .cast(pl.Float32).alias('border_color_interaction_2'),\n",
    "\n",
    "        pl.col('clin_size_long_diam_mm').truediv(pl.col('tbp_lv_deltaLBnorm'))\n",
    "        .cast(pl.Float32).alias('size_color_contrast_ratio'),\n",
    "\n",
    "        pl.col('tbp_lv_nevi_confidence').truediv(pl.col('age_approx'))\n",
    "        .cast(pl.Float32).alias('age_normalized_nevi_confidence'),\n",
    "\n",
    "        (pl.col('clin_size_long_diam_mm').pow(2).add(pl.col('age_approx').pow(2))).sqrt()\n",
    "        .cast(pl.Float32).alias('age_normalized_nevi_confidence_2'),\n",
    "\n",
    "        pl.col('tbp_lv_radial_color_std_max').mul(pl.col('tbp_lv_symm_2axis'))\n",
    "        .cast(pl.Float32).alias('color_asymmetry_index'),\n",
    "    ])\n",
    "    columns += ['symmetry_perimeter_interaction', 'comprehensive_lesion_index', 'color_variance_ratio', 'border_color_interaction', 'border_color_interaction_2', 'size_color_contrast_ratio', 'age_normalized_nevi_confidence', 'age_normalized_nevi_confidence_2', 'color_asymmetry_index']\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col('tbp_lv_areaMM2').mul(pl.col('tbp_lv_x').pow(2).add(pl.col('tbp_lv_y').pow(2)).add(pl.col('tbp_lv_z').pow(2)).sqrt())\n",
    "        .cast(pl.Float32).alias('volume_approximation_3d'),\n",
    "\n",
    "        pl.col('tbp_lv_L').sub(pl.col('tbp_lv_Lext')).abs().add(pl.col('tbp_lv_A').sub(pl.col('tbp_lv_Aext')).abs())\n",
    "        .add(pl.col('tbp_lv_B').sub(pl.col('tbp_lv_Bext')).abs())\n",
    "        .cast(pl.Float32).alias('color_range'),\n",
    "\n",
    "        pl.col('tbp_lv_eccentricity').mul(pl.col('tbp_lv_color_std_mean'))\n",
    "        .cast(pl.Float32).alias('shape_color_consistency'),\n",
    "\n",
    "        pl.col('tbp_lv_perimeterMM').truediv(pl.lit(2).mul(np.pi).mul(pl.col('tbp_lv_areaMM2').truediv(np.pi).sqrt()))\n",
    "        .cast(pl.Float32).alias('border_length_ratio'),\n",
    "\n",
    "        pl.col('age_approx').mul(pl.col('clin_size_long_diam_mm')).mul(pl.col('tbp_lv_symm_2axis'))\n",
    "        .cast(pl.Float32).alias('age_size_symmetry_index'),\n",
    "\n",
    "        pl.col('age_approx').mul(pl.col('tbp_lv_areaMM2')).mul(pl.col('tbp_lv_symm_2axis'))\n",
    "        .cast(pl.Float32).alias('index_age_size_symmetry'),\n",
    "            \n",
    "        pl.col('isic_id').count().over('patient_id')\n",
    "        .cast(pl.Int16).alias('count_per_patient'),\n",
    "    ])\n",
    "    columns += ['volume_approximation_3d', 'color_range', 'shape_color_consistency', 'border_length_ratio', 'age_size_symmetry_index', 'index_age_size_symmetry', 'count_per_patient']\n",
    "\n",
    "    # Apply z-score aggregation to all numeric (float dtype) columns: z-score = (x - mean) / std\n",
    "    z_score = [\n",
    "        pl.col(col).sub(pl.col(col).mean()).truediv(pl.col(col).std()).over('patient_id')\n",
    "        .cast(pl.Float32).alias(f'{col}_zscore') for col in df.columns if df[col].dtype == pl.Float32\n",
    "        ]\n",
    "    \n",
    "    columns += [f'{col}_zscore' for col in df.columns if df[col].dtype == pl.Float32]\n",
    "    df = df.with_columns(z_score)\n",
    "\n",
    "    df = df.to_pandas()\n",
    "    \n",
    "    return df, columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df_train, df_test, train_cols):\n",
    "    global cat_features\n",
    "    \n",
    "    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n",
    "    encoder.fit(df_train[cat_features])\n",
    "    \n",
    "    new_cat_features = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n",
    "\n",
    "    df_train[new_cat_features] = encoder.transform(df_train[cat_features])\n",
    "    df_train[new_cat_features] = df_train[new_cat_features].astype('category')\n",
    "\n",
    "    df_test[new_cat_features] = encoder.transform(df_test[cat_features])\n",
    "    df_test[new_cat_features] = df_test[new_cat_features].astype('category')\n",
    "\n",
    "    for col in cat_features:\n",
    "        train_cols.remove(col)\n",
    "\n",
    "    train_cols.extend(new_cat_features)\n",
    "    cat_features = new_cat_features\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Encoding & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta, new_num_columns = generate_features(train_metadata)\n",
    "test_meta, _ = generate_features(test_metadata)\n",
    "train_cols += new_num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta, test_meta = encode_categorical(train_meta, test_meta, train_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective':        'binary',\n",
    "    'verbosity':        -1,\n",
    "    'n_iter':           200,\n",
    "    'boosting_type':    'gbdt',\n",
    "    'random_state':     SEED,\n",
    "    'lambda_l1':        0.08758718919397321, \n",
    "    'lambda_l2':        0.0039689175176025465, \n",
    "    'learning_rate':    0.03231007103195577, \n",
    "    'max_depth':        4, \n",
    "    'num_leaves':       103, \n",
    "    'colsample_bytree': 0.8329551585827726, \n",
    "    'colsample_bynode': 0.4025961355653304, \n",
    "    'bagging_fraction': 0.7738954452473223, \n",
    "    'bagging_freq':     4, \n",
    "    'min_data_in_leaf': 85, \n",
    "    'scale_pos_weight': 2.7984184778875543,\n",
    "}\n",
    "\n",
    "lgb_model = Pipeline([\n",
    "    ('classifier', lgb.LGBMClassifier(**lgb_params)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_params = {\n",
    "    'loss_function':     'Logloss',\n",
    "    'iterations':        200,\n",
    "    'verbose':           False,\n",
    "    'random_state':      SEED,\n",
    "    'max_depth':         7, \n",
    "    'learning_rate':     0.06936242010150652, \n",
    "    'scale_pos_weight':  2.6149345838209532, \n",
    "    'l2_leaf_reg':       6.216113851699493, \n",
    "    'subsample':         0.6249261779711819, \n",
    "    'min_data_in_leaf':  24,\n",
    "    'cat_features':      cat_features,\n",
    "}\n",
    "\n",
    "cb_model = Pipeline([\n",
    "    ('classifier', cb.CatBoostClassifier(**cb_params)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'enable_categorical': True,\n",
    "    'tree_method':        'hist',\n",
    "    'random_state':       SEED,\n",
    "    'learning_rate':      0.08501257473292347, \n",
    "    'lambda':             8.879624125465703, \n",
    "    'alpha':              0.6779926606782505, \n",
    "    'max_depth':          6, \n",
    "    'subsample':          0.6012681388711075, \n",
    "    'colsample_bytree':   0.8437772277074493, \n",
    "    'colsample_bylevel':  0.5476090898823716, \n",
    "    'colsample_bynode':   0.9928601203635129, \n",
    "    'scale_pos_weight':   3.29440313334688,\n",
    "}\n",
    "\n",
    "xgb_model = Pipeline([\n",
    "    ('classifier', xgb.XGBClassifier(**xgb_params)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_estimator = VotingClassifier([\n",
    "    ('lgb', lgb_model), ('cb', cb_model), ('xgb', xgb_model),\n",
    "], voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Partial AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(estimator, X, y_true):\n",
    "    y_hat = estimator.predict_proba(X)[:, 1]\n",
    "    min_tpr = 0.80\n",
    "    max_fpr = abs(1 - min_tpr)\n",
    "    \n",
    "    v_gt = abs(y_true - 1)\n",
    "    v_pred = np.array([1.0 - x for x in y_hat])\n",
    "    \n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    \n",
    "    return partial_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_groups(df, group_split = 10):\n",
    "    train_groups = []\n",
    "\n",
    "    # Get the positive and negative samples\n",
    "    pos_samples = df[df.target == 1].reset_index(drop=True)\n",
    "    neg_samples = df[df.target == 0].reset_index(drop=True)\n",
    "\n",
    "    # Split the negative samples into 10 groups\n",
    "    neg_samples['group'] = neg_samples.index % group_split\n",
    "    \n",
    "    # Concatenate the positive samples with the negative samples\n",
    "    for i in range(group_split):\n",
    "        train_group = pd.concat([pos_samples, neg_samples[neg_samples['group'] == i]]).reset_index(drop=True)\n",
    "        train_groups.append(train_group)\n",
    "\n",
    "    return train_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(metadata, train_cols, cv):\n",
    "\n",
    "    X = metadata[train_cols]\n",
    "    y = metadata[target_col]\n",
    "    groups = metadata[group_col]\n",
    "\n",
    "    models = {\n",
    "        'fold1': [],\n",
    "        'fold2': [],\n",
    "        'fold3': [],\n",
    "        'fold4': [],\n",
    "        'fold5': []\n",
    "    }\n",
    "\n",
    "    scores = {\n",
    "        'fold1': [],\n",
    "        'fold2': [],\n",
    "        'fold3': [],\n",
    "        'fold4': [],\n",
    "        'fold5': []\n",
    "    }\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y, groups)):\n",
    "\n",
    "        train_df = metadata.loc[train_idx].reset_index(drop=True)\n",
    "        valid_df = metadata.loc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "        train_groups = get_train_groups(train_df)\n",
    "\n",
    "        for i, train_group in enumerate(tqdm(train_groups, desc=f'Fold {fold+1}')):\n",
    "\n",
    "            X_train, X_valid = train_group[train_cols], valid_df[train_cols]\n",
    "            y_train, y_valid = train_group[target_col], valid_df[target_col]\n",
    "\n",
    "            model = soft_estimator.fit(X_train, y_train)\n",
    "\n",
    "            score = custom_metric(model, X_valid, y_valid)\n",
    "        \n",
    "            models[f'fold{fold+1}'].append(model)\n",
    "            scores[f'fold{fold+1}'].append(score)\n",
    "\n",
    "        print(f'Scores: {scores[f\"fold{fold+1}\"]}')\n",
    "        print(f'Fold {fold+1} - Mean PAUC: {np.mean(scores[f\"fold{fold+1}\"])}')\n",
    "\n",
    "    return models, scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c09b16872947ff9710c9f97e4c6ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 1:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "XGBoostError",
     "evalue": "[21:17:20] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\nStack trace:\n  [bt] (0) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7f013d42dbbc]\n  [bt] (1) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x52daae) [0x7f013d72daae]\n  [bt] (2) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x51b5fd) [0x7f013d71b5fd]\n  [bt] (3) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x51d82c) [0x7f013d71d82c]\n  [bt] (4) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x4cce3a) [0x7f013d6cce3a]\n  [bt] (5) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7f013d34546c]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7f02602d7e2e]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7f02602d4493]\n  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7f02605543e9]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[239], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m models, scores \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msgkf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[238], line 35\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(metadata, train_cols, cv)\u001b[0m\n\u001b[1;32m     32\u001b[0m X_train, X_valid \u001b[38;5;241m=\u001b[39m train_group[train_cols], valid_df[train_cols]\n\u001b[1;32m     33\u001b[0m y_train, y_valid \u001b[38;5;241m=\u001b[39m train_group[target_col], valid_df[target_col]\n\u001b[0;32m---> 35\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msoft_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m score \u001b[38;5;241m=\u001b[39m custom_metric(model, X_valid, y_valid)\n\u001b[1;32m     39\u001b[0m models[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(model)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:366\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    364\u001b[0m transformed_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:89\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m     )\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVoting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_base.py:36\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m---> 36\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/pipeline.py:333\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    332\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 333\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1512\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m-> 1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1532\u001b[0m     params,\n\u001b[1;32m   1533\u001b[0m     train_dmatrix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m   1543\u001b[0m )\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:596\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    577\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m    578\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    592\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    593\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 596\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1003\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1003\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuantileDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_bin\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:1573\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   1554\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m         )\n\u001b[1;32m   1567\u001b[0m     ):\n\u001b[1;32m   1568\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1570\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1571\u001b[0m         )\n\u001b[0;32m-> 1573\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:1634\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[0;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[1;32m   1632\u001b[0m it\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[0;32m-> 1634\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:284\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [21:17:20] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\nStack trace:\n  [bt] (0) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7f013d42dbbc]\n  [bt] (1) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x52daae) [0x7f013d72daae]\n  [bt] (2) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x51b5fd) [0x7f013d71b5fd]\n  [bt] (3) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x51d82c) [0x7f013d71d82c]\n  [bt] (4) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x4cce3a) [0x7f013d6cce3a]\n  [bt] (5) /home/bracs/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7f013d34546c]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7f02602d7e2e]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7f02602d4493]\n  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7f02605543e9]\n\n"
     ]
    }
   ],
   "source": [
    "models, scores = train(train_meta, train_cols, sgkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average PAUC: {np.mean([np.mean(scores[f\"fold{i+1}\"]) for i in range(N_SPLITS)])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
