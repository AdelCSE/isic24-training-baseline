{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append('../..')\n",
    "from src.utils import load_env_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {DEVICE} for inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR, _, _ = load_env_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNDER_SAMPLING_RATIO = 0.01\n",
    "OVER_SAMPLING_RATIO = 0.003\n",
    "\n",
    "N_SPLITS = 5\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed : int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_META_PATH = os.path.join(DATA_DIR, 'isic_2024/train-metadata.csv')\n",
    "TEST_META_PATH = os.path.join(DATA_DIR, 'isic_2024/test-metadata.csv')\n",
    "\n",
    "IMG_FEATURES = os.path.join(DATA_DIR, 'isic_2024/features.csv')\n",
    "EVA_FEATURES = os.path.join(DATA_DIR, 'isic_2024/train_eva02_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(TRAIN_META_PATH)\n",
    "test_metadata = pd.read_csv(TEST_META_PATH)\n",
    "\n",
    "eva_features = pd.read_csv(EVA_FEATURES)\n",
    "img_features = pd.read_csv(IMG_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Train Only Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [col for col in train_metadata.columns if col not in test_metadata and col != 'target']\n",
    "train_metadata.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "splits = list(sgkf.split(X=train_metadata, y=train_metadata.target, groups=train_metadata.patient_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_eva_preds = []\n",
    "\n",
    "for i,(train_idx,val_idx) in enumerate(splits):\n",
    "    a = eva_features[['isic_id',f'eva02_fold{i}']].iloc[val_idx]\n",
    "    a['eva02'] = a[f'eva02_fold{i}']\n",
    "    a = a.drop(columns=[f'eva02_fold{i}'])\n",
    "    oof_eva_preds.append(a)\n",
    "\n",
    "oof_eva_preds = pd.concat(oof_eva_preds)\n",
    "\n",
    "#train_metadata = train_metadata.merge(oof_eva_preds, on='isic_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features = img_features.drop(columns=[\"resnet18\",\"coat_lite_tiny\",\"swin_tiny_patch4_window7_224\"])\n",
    "#train_metadata = train_metadata.merge(img_features, on='isic_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the categorical & numerical columns\n",
    "categorical_cols = train_metadata.select_dtypes(include=[object]).columns.tolist()\n",
    "numerical_cols = train_metadata.select_dtypes(include=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col, target_col, group_col = 'isic_id', 'target', 'patient_id'\n",
    "\n",
    "irrelevant_cols = ['isic_id', 'patient_id', 'image_type', 'copyright_license', 'target']\n",
    "\n",
    "# Filter out irrelevant columns\n",
    "cat_features = [col for col in categorical_cols if col not in irrelevant_cols]\n",
    "num_features = [col for col in numerical_cols if col not in irrelevant_cols]\n",
    "\n",
    "# Train columns\n",
    "train_cols = cat_features + num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values of numerical columns with median\n",
    "for feature in num_features:\n",
    "    median = train_metadata[feature].median()\n",
    "    train_metadata[feature] = train_metadata[feature].fillna(median)\n",
    "    #test_metadata[feature] = test_metadata[feature].fillna(median)\n",
    "\n",
    "# Fill missing values of categorical columns with 'missing'\n",
    "train_metadata[cat_features] = train_metadata[cat_features].fillna('missing')\n",
    "#test_metadata[cat_features] = test_metadata[cat_features].fillna('missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ABCDE criteria features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_abcde_features(metadata: pd.DataFrame):\n",
    "\n",
    "    epsilon = 1e-8 # To avoid division by zero\n",
    "    columns = []\n",
    "\n",
    "    pl_df = pl.DataFrame(metadata)\n",
    "\n",
    "    # Diameter: Melanoma growths are normally larger than 6mm in diameter, which is about the diameter of a standard pencil eraser\n",
    "\n",
    "    pl_df = pl_df.with_columns([\n",
    "        # Diameter ratio: This is a measure of how elongated the mole is. A perfectly round mole has an axis ratio of 1.0\n",
    "        pl.col('tbp_lv_minorAxisMM').truediv(pl.col('clin_size_long_diam_mm') + epsilon)\n",
    "        .cast(pl.Float32).alias('diam_ratio'),\n",
    "\n",
    "        # Diameter difference: Difference between the long diameter and minor axis\n",
    "        pl.col('clin_size_long_diam_mm').sub(pl.col('tbp_lv_minorAxisMM'))\n",
    "        .cast(pl.Float32).alias('diam_difference'),\n",
    "\n",
    "        # Long diameter greater than 6mm\n",
    "        pl.when(pl.col('clin_size_long_diam_mm') > 6).then(1.0).otherwise(0.0)\n",
    "        .cast(pl.Float32).alias('long_diam_gt_6mm'),\n",
    "\n",
    "        # Minor axis greater than 6mm\n",
    "        pl.when(pl.col('tbp_lv_minorAxisMM') > 6).then(1.0).otherwise(0.0)\n",
    "        .cast(pl.Float32).alias('short_diam_gt_6mm')\n",
    "    ])\n",
    "    columns += ['diam_ratio', 'diam_difference', 'long_diam_gt_6mm', 'short_diam_gt_6mm']\n",
    "\n",
    "\n",
    "    # Evolution: Melanoma lesions often change in size, shape, color, or texture over time, while non-cancerous moles usually stay the same\n",
    "    pl_df = pl_df.with_columns([\n",
    "        # Position of the mole in the 3d space\n",
    "        (pl.col('tbp_lv_x').pow(2) + pl.col('tbp_lv_y').pow(2) + pl.col('tbp_lv_z').pow(2)).sqrt()\n",
    "        .cast(pl.Float32).alias('3d_position'),\n",
    "\n",
    "        # Perimeter area ratio\n",
    "        pl.col('tbp_lv_perimeterMM').truediv(pl.col('tbp_lv_areaMM2') + epsilon)\n",
    "        .cast(pl.Float32).alias('perim_area_ratio'),\n",
    "\n",
    "        # log area\n",
    "        pl.col('tbp_lv_areaMM2').log().cast(pl.Float32).alias('log_area'),\n",
    "\n",
    "        # log perimeter\n",
    "        pl.col('tbp_lv_perimeterMM').log().cast(pl.Float32).alias('log_perimeter'),\n",
    "\n",
    "        # Roundness: This is a measure of how round the mole is. A perfectly round mole has a roundness index of 1.0\n",
    "        pl.col('tbp_lv_areaMM2').mul(4 * np.pi).truediv(pl.col('tbp_lv_perimeterMM').pow(2) + epsilon)\n",
    "        .cast(pl.Float32).alias('roundness_index'),\n",
    "    ])\n",
    "    columns += ['3d_position', 'perim_area_ratio', 'log_area', 'log_perimeter', 'roundness_index']\n",
    "\n",
    "\n",
    "    # Asymmetry: Melanoma is often asymmetrical, which means the shape isn't uniform, Non-cancerous moles are typically uniform and symmetrical\n",
    "    pl_df = pl_df.with_columns([\n",
    "        # Asymmetry angle sinus\n",
    "        pl.col('tbp_lv_symm_2axis_angle').sin()\n",
    "        .cast(pl.Float32).alias('asymmetry_angle_sin'),\n",
    "\n",
    "        # Asymmetry angle cosinus\n",
    "        pl.col('tbp_lv_symm_2axis_angle').cos()\n",
    "        .cast(pl.Float32).alias('asymmetry_angle_cos'),\n",
    "\n",
    "        # Asymmetry index\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_eccentricity'))\n",
    "        .cast(pl.Float32).alias('symmetry_index'),\n",
    "\n",
    "        # Symmetry border interaction\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_norm_border'))\n",
    "        .cast(pl.Float32).alias('symmetry_border_interaction'),\n",
    "\n",
    "        # Symmetry eccentricity interaction\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_eccentricity'))\n",
    "        .cast(pl.Float32).alias('symmetry_eccentricity_interaction'),\n",
    "\n",
    "        # Symmetry color interaction\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_radial_color_std_max'))\n",
    "        .cast(pl.Float32).alias('symmetry_color_interaction'),\n",
    "\n",
    "        # Symmetry border jaggedness interaction\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_area_perim_ratio'))\n",
    "        .cast(pl.Float32).alias('symmetry_border_jaggedness_interaction'),\n",
    "    ])\n",
    "    columns += ['asymmetry_angle_sin', 'asymmetry_angle_cos', 'symmetry_index', 'symmetry_border_interaction', 'symmetry_eccentricity_interaction', 'symmetry_color_interaction', 'symmetry_border_jaggedness_interaction']\n",
    "\n",
    "\n",
    "    # Color: Melanoma lesions are often more than one color or shade, Moles that are benign are usually one color\n",
    "    pl_df = pl_df.with_columns([\n",
    "        # Color std ratio\n",
    "        pl.col('tbp_lv_color_std_mean').truediv(pl.col('tbp_lv_radial_color_std_max') + epsilon)\n",
    "        .cast(pl.Float32).alias('color_std_ratio'),\n",
    "\n",
    "        (pl.col('tbp_lv_L').sub(pl.col('tbp_lv_Lext')) + pl.col('tbp_lv_A').sub(pl.col('tbp_lv_Aext')) + pl.col('tbp_lv_B').sub(pl.col('tbp_lv_Bext')))\n",
    "        .truediv((pl.col('tbp_lv_L') + pl.col('tbp_lv_A') + pl.col('tbp_lv_B') + epsilon))\n",
    "        .cast(pl.Float32).alias('color_difference_ratio'),\n",
    "\n",
    "        (pl.col('tbp_lv_deltaA')**2 + pl.col('tbp_lv_deltaB')**2 + pl.col('tbp_lv_deltaL')**2).sqrt()\n",
    "        .cast(pl.Float32).alias('color_euclidean_distance'),\n",
    "\n",
    "        # Color eccentricity interaction\n",
    "        pl.col('tbp_lv_radial_color_std_max').mul(pl.col('tbp_lv_eccentricity'))\n",
    "        .cast(pl.Float32).alias('color_eccentricity_interaction'),\n",
    "\n",
    "        pl.col('tbp_lv_L').sub(pl.col('tbp_lv_L').mean()).truediv(pl.col('tbp_lv_stdL') + epsilon)\n",
    "        .cast(pl.Float32).alias('L_normalized'),\n",
    "\n",
    "        # H Contrast\n",
    "        pl.col('tbp_lv_H').sub(pl.col('tbp_lv_Hext'))\n",
    "        .cast(pl.Float32).alias('H_contrast'),\n",
    "\n",
    "        # L Contrast\n",
    "        pl.col('tbp_lv_L').sub(pl.col('tbp_lv_Lext'))\n",
    "        .cast(pl.Float32).alias('L_contrast'),\n",
    "\n",
    "        # A Contrast\n",
    "        pl.col('tbp_lv_A').sub(pl.col('tbp_lv_Aext'))\n",
    "        .cast(pl.Float32).alias('A_contrast'),\n",
    "\n",
    "        # B Contrast\n",
    "        pl.col('tbp_lv_B').sub(pl.col('tbp_lv_Bext'))\n",
    "        .cast(pl.Float32).alias('B_contrast'),\n",
    "\n",
    "        # C Contrast\n",
    "        pl.col('tbp_lv_C').sub(pl.col('tbp_lv_Cext'))\n",
    "        .cast(pl.Float32).alias('C_contrast'),\n",
    "\n",
    "        # A/B ratio\n",
    "        pl.col('tbp_lv_deltaA').truediv(pl.col('tbp_lv_deltaB') + epsilon)\n",
    "        .cast(pl.Float32).alias('A_B_ratio'),\n",
    "\n",
    "        # L uniformity\n",
    "        pl.col('tbp_lv_L').sub(pl.col('tbp_lv_Lext')).truediv(pl.col('tbp_lv_L') + epsilon)\n",
    "        .cast(pl.Float32).alias('L_uniformity'),\n",
    "\n",
    "        # A uniformity\n",
    "        pl.col('tbp_lv_A').sub(pl.col('tbp_lv_Aext')).truediv(pl.col('tbp_lv_A') + epsilon)\n",
    "        .cast(pl.Float32).alias('A_uniformity'),\n",
    "\n",
    "        # B uniformity\n",
    "        pl.col('tbp_lv_B').sub(pl.col('tbp_lv_Bext')).truediv(pl.col('tbp_lv_B') + epsilon)\n",
    "        .cast(pl.Float32).alias('B_uniformity'),\n",
    "\n",
    "        # C uniformity\n",
    "        pl.col('tbp_lv_C').sub(pl.col('tbp_lv_Cext')).truediv(pl.col('tbp_lv_C') + epsilon)\n",
    "        .cast(pl.Float32).alias('C_uniformity'),\n",
    "\n",
    "        # H uniformity ratio\n",
    "        pl.col('tbp_lv_H').sub(pl.col('tbp_lv_Hext')).truediv(pl.col('tbp_lv_H') + epsilon)\n",
    "        .cast(pl.Float32).alias('H_uniformity_ratio'),\n",
    "\n",
    "        pl.col('tbp_lv_deltaA').add(pl.col('tbp_lv_deltaB')).add(pl.col('tbp_lv_deltaL'))\n",
    "        .cast(pl.Float32).alias('delta_sum'),\n",
    "    ])\n",
    "    columns += ['color_std_ratio', 'color_difference_ratio', 'color_euclidean_distance', 'color_eccentricity_interaction', 'L_normalized', 'H_contrast', 'L_contrast', 'A_contrast', 'B_contrast', 'C_contrast', 'A_B_ratio', 'L_uniformity', 'A_uniformity', 'B_uniformity', 'C_uniformity', 'H_uniformity_ratio', 'delta_sum']\n",
    "\n",
    "    pl_df = pl_df.with_columns([\n",
    "        # lesions count by patient\n",
    "        pl.col('isic_id').count().over('patient_id').alias('lesions_count_by_patient'),\n",
    "        \n",
    "        #(pl.col('eva02') + pl.col('eva02_tiny_patch14_224') + pl.col('coat_lite_tiny_2')).truediv(3)\n",
    "        #.cast(pl.Float32).alias('image_features_ensemble')\n",
    "    ])\n",
    "    columns += ['lesions_count_by_patient']\n",
    "    \n",
    "    pd_df = pl_df.to_pandas()\n",
    "    \n",
    "    numericalc_cols = pd_df.select_dtypes(np.number).columns\n",
    "    \n",
    "    for col in numericalc_cols:\n",
    "        pd_df[col] = pd_df[col].replace(np.inf, 1e8).replace(-np.inf, -1e8)\n",
    "\n",
    "    return pd_df, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata, new_features = generate_abcde_features(train_metadata)\n",
    "#test_metadata = generate_abcde_features(test_metadata)\n",
    "\n",
    "train_cols += new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Z-Score features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_zscore_features(metadata: pd.DataFrame):\n",
    "    epsilon = 1e-8\n",
    "    columns = []\n",
    "    numerical_cols = metadata.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df = pl.DataFrame(metadata)\n",
    "\n",
    "    # Apply z-score aggregation to all numeric (float dtype) columns: z-score = (x - mean) / std\n",
    "    z_score = [\n",
    "        (pl.col(col).sub(pl.col(col).mean())).truediv(pl.col(col).std() + epsilon).over('patient_id')\n",
    "        .cast(pl.Float32).alias(f'{col}_zscore') for col in numerical_cols if col != 'target'\n",
    "        ]\n",
    "    \n",
    "    columns += [f'{col}_zscore' for col in numerical_cols if col != 'target']\n",
    "    df = df.with_columns(z_score)\n",
    "\n",
    "    df = df.to_pandas()\n",
    "    \n",
    "    return df, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata, new_features = generate_zscore_features(train_metadata)\n",
    "test_metadata, _ = generate_zscore_features(test_metadata)\n",
    "\n",
    "train_cols += new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stats aggregations on img features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aggregated_features(metadata: pd.DataFrame, features: list):\n",
    "    columns = []\n",
    "    df = pl.DataFrame(metadata)\n",
    "\n",
    "    # Apply aggregation functions to specified columns\n",
    "    min_agg = [pl.col(col).min().over('patient_id').alias(f'{col}_min_by_patient') for col in features]\n",
    "    max_agg = [pl.col(col).max().over('patient_id').alias(f'{col}_max_by_patient') for col in features]\n",
    "    mean_agg = [pl.col(col).mean().over('patient_id').alias(f'{col}_mean_by_patient') for col in features]\n",
    "    std_agg = [pl.col(col).std().over('patient_id').alias(f'{col}_std_by_patient') for col in features]\n",
    "    median_agg = [pl.col(col).median().over('patient_id').alias(f'{col}_median_by_patient') for col in features]\n",
    "    skew_agg = [pl.col(col).skew().over('patient_id').alias(f'{col}_skew_by_patient') for col in features]\n",
    "    q25_agg = [pl.col(col).quantile(0.25).over('patient_id').alias(f'{col}_q25_by_patient') for col in features]\n",
    "    q75_agg = [pl.col(col).quantile(0.75).over('patient_id').alias(f'{col}_q75_by_patient') for col in features]\n",
    "\n",
    "    columns += [f'{col}_{agg}_by_patient' for col in features for agg in ['min', 'max', 'mean', 'std', 'median', 'skew', 'q25', 'q75']]\n",
    "\n",
    "    df = df.with_columns(min_agg + max_agg + mean_agg + std_agg + median_agg + skew_agg + q25_agg + q75_agg)\n",
    "\n",
    "    df = df.to_pandas()\n",
    "    \n",
    "    return df, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_features = ['tbp_lv_nevi_confidence']\n",
    "\n",
    "train_metadata, new_features = generate_aggregated_features(train_metadata, stats_features)\n",
    "#test_metadata, _ = generate_aggregated_features(test_metadata, num_features)\n",
    "\n",
    "train_cols += new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = train_metadata.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_features = [col for col in numerical_cols if col not in irrelevant_cols]\n",
    "\n",
    "# Fill missing values of numerical columns with median\n",
    "for feature in num_features:\n",
    "    median = train_metadata[feature].median()\n",
    "    train_metadata[feature] = train_metadata[feature].fillna(median)\n",
    "    #test_metadata[feature] = test_metadata[feature].fillna(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df_train, df_test, cat_features):\n",
    "    \n",
    "    encoder = OrdinalEncoder(\n",
    "        categories='auto',\n",
    "        dtype=np.int32,\n",
    "        handle_unknown='use_encoded_value',\n",
    "        unknown_value=-2,\n",
    "        encoded_missing_value=-1,\n",
    "    )\n",
    "\n",
    "    df_train[cat_features] = encoder.fit_transform(df_train[cat_features])\n",
    "    df_test[cat_features] = encoder.transform(df_test[cat_features])\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata, test_metadata = encode_categorical(train_metadata, test_metadata, cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pauc_score(estimator, X, y_true):\n",
    "    y_hat = estimator.predict_proba(X)[:, 1]\n",
    "    min_tpr = 0.80\n",
    "    max_fpr = abs(1 - min_tpr)\n",
    "    \n",
    "    v_gt = abs(y_true - 1)\n",
    "    v_pred = np.array([1.0 - x for x in y_hat])\n",
    "    \n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    \n",
    "    return partial_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oof_pauc(y_true, y_hat):\n",
    "    min_tpr = 0.80\n",
    "    max_fpr = abs(1 - min_tpr)\n",
    "    \n",
    "    v_gt = abs(y_true - 1)\n",
    "    v_pred = np.array([1.0 - x for x in y_hat])\n",
    "    \n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    \n",
    "    return partial_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_best_params = {\n",
    "    'random_state': SEED,\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_iter': 217,\n",
    "    'learning_rate': 0.03238691082828724,\n",
    "    'min_data_in_leaf': 93,\n",
    "    'colsample_bytree': 0.6336220063217671,\n",
    "    'colsample_bynode': 0.6449520328952557,\n",
    "    'bagging_fraction': 0.4759532875970691,\n",
    "    'bagging_freq': 5,        \n",
    "    'lambda_l1': 0.26214445542677706,\n",
    "    'lambda_l2': 0.5374677609248407,\n",
    "    'num_leaves': 107,\n",
    "    'max_depth': 6,\n",
    "    'min_child_samples': 38,\n",
    "    'scale_pos_weight': 2.454410437484347,\n",
    "    'verbosity': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_best_params = {\n",
    "    'random_state': SEED,\n",
    "    'loss_function': 'Logloss',\n",
    "    'iterations': 240,\n",
    "    'learning_rate': 0.046047767547706654,\n",
    "    'scale_pos_weight': 4.670443106586375,\n",
    "    'reg_lambda': 6.153764402866752,\n",
    "    'subsample': 0.4712307759317672,\n",
    "    'min_data_in_leaf': 26,\n",
    "    'max_depth': 4,\n",
    "    'cat_features': cat_features,\n",
    "    'verbose': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_params = {\n",
    "    'random_state': SEED,\n",
    "    'tree_method': 'hist',\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.09211299188601348,\n",
    "    'colsample_bytree': 0.8178496272146406,\n",
    "    'colsample_bynode': 0.8688187031865214,\n",
    "    'colsample_bylevel': 0.3476250413253686,\n",
    "    'scale_pos_weight': 2.1101053079075625,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.7286594187699229,\n",
    "    'lambda': 4.586386144644716,\n",
    "    'alpha': 0.21956352903435347,\n",
    "    'enable_categorical': True,\n",
    "    'verbosity': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_metadata[train_cols]\n",
    "y = train_metadata[target_col]\n",
    "groups = train_metadata[group_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Cross-Validation on 5 folds\n",
      "\n",
      "Fold 1 - LGB: 0.1596 - CB: 0.1472 - XGB: 0.1673 - Ensemble: 0.1537\n",
      "\n",
      "Fold 2 - LGB: 0.1689 - CB: 0.1688 - XGB: 0.1688 - Ensemble: 0.1703\n",
      "\n",
      "Fold 3 - LGB: 0.1816 - CB: 0.1800 - XGB: 0.1829 - Ensemble: 0.1824\n",
      "\n",
      "Fold 4 - LGB: 0.1695 - CB: 0.1634 - XGB: 0.1659 - Ensemble: 0.1667\n",
      "\n",
      "Fold 5 - LGB: 0.1694 - CB: 0.1512 - XGB: 0.1665 - Ensemble: 0.1596\n",
      "\n",
      "Average Scores - LGB: 0.1698 - CB: 0.1621 - XGB: 0.1703 - Ensemble: 0.1665 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = {\n",
    "    'lgb': [],\n",
    "    'cb': [],\n",
    "    'xgb': [],\n",
    "    'soft': [],\n",
    "}\n",
    "\n",
    "preds = {\n",
    "    'lgb': [],\n",
    "    'cb': [],\n",
    "    'xgb': [],\n",
    "    'soft': [],\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'lgb': [],\n",
    "    'cb': [],\n",
    "    'xgb': [],\n",
    "    'soft': [],\n",
    "}\n",
    "\n",
    "y_val = []\n",
    "\n",
    "print(f'Starting Cross-Validation on {N_SPLITS} folds\\n')\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(sgkf.split(X, y, groups)):\n",
    "\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    y_val.extend(y_valid)\n",
    "    \n",
    "    lgb_model = Pipeline([\n",
    "        ('sampler1', RandomOverSampler(sampling_strategy=OVER_SAMPLING_RATIO, random_state=SEED)),\n",
    "        ('sampler2', RandomUnderSampler(sampling_strategy=UNDER_SAMPLING_RATIO, random_state=SEED)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_best_params)),\n",
    "    ])\n",
    "\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    lgb_preds = lgb_model.predict_proba(X_valid)[:,1]\n",
    "    lgb_score = pauc_score(lgb_model, X_valid, y_valid)\n",
    "\n",
    "    cb_model = Pipeline([\n",
    "        ('sampler1', RandomOverSampler(sampling_strategy= 0.003 , random_state=SEED)),\n",
    "        ('sampler2', RandomUnderSampler(sampling_strategy=0.01, random_state=SEED)),\n",
    "        ('classifier', cb.CatBoostClassifier(**cb_best_params)),\n",
    "    ])\n",
    "\n",
    "    cb_model.fit(X_train, y_train)\n",
    "    cb_preds = cb_model.predict_proba(X_valid)[:,1]\n",
    "    cb_score = pauc_score(cb_model, X_valid, y_valid)\n",
    "\n",
    "    xgb_model = Pipeline([\n",
    "        ('sampler1', RandomOverSampler(sampling_strategy= 0.003 , random_state=SEED)),\n",
    "        ('sampler2', RandomUnderSampler(sampling_strategy=0.01, random_state=SEED)),\n",
    "        ('classifier', xgb.XGBClassifier(**xgb_best_params)),\n",
    "    ])\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_preds = xgb_model.predict_proba(X_valid)[:,1]\n",
    "    xgb_score = pauc_score(xgb_model, X_valid, y_valid)\n",
    "\n",
    "    soft_preds = lgb_preds + cb_preds + xgb_preds / 3\n",
    "    soft_score = oof_pauc(y_valid, soft_preds)\n",
    "\n",
    "    scores['lgb'].append(lgb_score)\n",
    "    scores['cb'].append(cb_score)\n",
    "    scores['xgb'].append(xgb_score)\n",
    "    scores['soft'].append(soft_score)\n",
    "\n",
    "    models['lgb'].append(lgb_model)\n",
    "    models['cb'].append(cb_model)\n",
    "    models['xgb'].append(xgb_model)\n",
    "    \n",
    "    preds['lgb'].extend(lgb_preds)\n",
    "    preds['cb'].extend(cb_preds)\n",
    "    preds['xgb'].extend(xgb_preds)\n",
    "    preds['soft'].extend(soft_preds)\n",
    "\n",
    "    print(f'Fold {fold + 1} - LGB: {lgb_score:.4f} - CB: {cb_score:.4f} - XGB: {xgb_score:.4f} - Ensemble: {soft_score:.4f}\\n')\n",
    "\n",
    "print(f'Average Scores - LGB: {np.mean(scores[\"lgb\"]):.4f} - CB: {np.mean(scores[\"cb\"]):.4f} - XGB: {np.mean(scores[\"xgb\"]):.4f} - Ensemble: {np.mean(scores[\"soft\"]):.4f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb</th>\n",
       "      <th>cb</th>\n",
       "      <th>xgb</th>\n",
       "      <th>soft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.159583</td>\n",
       "      <td>0.147197</td>\n",
       "      <td>0.167295</td>\n",
       "      <td>0.153678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.168929</td>\n",
       "      <td>0.168750</td>\n",
       "      <td>0.168767</td>\n",
       "      <td>0.170296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.181629</td>\n",
       "      <td>0.180032</td>\n",
       "      <td>0.182920</td>\n",
       "      <td>0.182382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.169544</td>\n",
       "      <td>0.163434</td>\n",
       "      <td>0.165863</td>\n",
       "      <td>0.166698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169381</td>\n",
       "      <td>0.151239</td>\n",
       "      <td>0.166498</td>\n",
       "      <td>0.159645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.169813</td>\n",
       "      <td>0.162131</td>\n",
       "      <td>0.170269</td>\n",
       "      <td>0.166540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.007004</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oof</th>\n",
       "      <td>0.168786</td>\n",
       "      <td>0.159286</td>\n",
       "      <td>0.169054</td>\n",
       "      <td>0.164272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lgb        cb       xgb      soft\n",
       "0     0.159583  0.147197  0.167295  0.153678\n",
       "1     0.168929  0.168750  0.168767  0.170296\n",
       "2     0.181629  0.180032  0.182920  0.182382\n",
       "3     0.169544  0.163434  0.165863  0.166698\n",
       "4     0.169381  0.151239  0.166498  0.159645\n",
       "mean  0.169813  0.162131  0.170269  0.166540\n",
       "std   0.007004  0.011896  0.006400  0.009778\n",
       "oof   0.168786  0.159286  0.169054  0.164272"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_scores = {\n",
    "    'lgb': oof_pauc(np.array(y_val), np.array(preds['lgb'])),\n",
    "    'cb': oof_pauc(np.array(y_val), np.array(preds['cb'])),\n",
    "    'xgb': oof_pauc(np.array(y_val), np.array(preds['xgb'])),\n",
    "    'soft': oof_pauc(np.array(y_val), np.array(preds['soft']))\n",
    "}\n",
    "\n",
    "eval_df = pd.DataFrame(scores)\n",
    "eval_df.loc['mean'] = eval_df.mean(axis=0)\n",
    "eval_df.loc['std'] = eval_df.std(axis=0)\n",
    "eval_df.loc['oof'] = oof_scores\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>lgb</th>\n",
       "      <th>cb</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015670</td>\n",
       "      <td>IP_1235828</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.000411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015845</td>\n",
       "      <td>IP_8170065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705232</td>\n",
       "      <td>0.936068</td>\n",
       "      <td>0.934974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015864</td>\n",
       "      <td>IP_6724798</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0015902</td>\n",
       "      <td>IP_4111386</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.001001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0024200</td>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  patient_id  target       lgb        cb       xgb\n",
       "0  ISIC_0015670  IP_1235828       0  0.000327  0.003275  0.000411\n",
       "1  ISIC_0015845  IP_8170065       0  0.705232  0.936068  0.934974\n",
       "2  ISIC_0015864  IP_6724798       0  0.000188  0.004573  0.000351\n",
       "3  ISIC_0015902  IP_4111386       0  0.000577  0.004582  0.001001\n",
       "4  ISIC_0024200  IP_8313778       0  0.001121  0.006794  0.000599"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save oof preds from each model as featue in new dataframe\n",
    "gbdt_data = pd.DataFrame({'isic_id': train_metadata['isic_id'], 'patient_id': train_metadata['patient_id'], 'target': train_metadata['target']})\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(sgkf.split(X, y, groups)):\n",
    "\n",
    "    gbdt_data.loc[val_idx, 'lgb'] = models['lgb'][fold].predict_proba(X.iloc[val_idx])[:,1]\n",
    "    gbdt_data.loc[val_idx, 'cb'] = models['cb'][fold].predict_proba(X.iloc[val_idx])[:,1]\n",
    "    gbdt_data.loc[val_idx, 'xgb'] = models['xgb'][fold].predict_proba(X.iloc[val_idx])[:,1]\n",
    "\n",
    "gbdt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_data = gbdt_data.merge(oof_eva_preds, on='isic_id')\n",
    "gbdt_data = gbdt_data.merge(img_features, on='isic_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>lgb</th>\n",
       "      <th>cb</th>\n",
       "      <th>xgb</th>\n",
       "      <th>eva02</th>\n",
       "      <th>eva02_tiny_patch14_224</th>\n",
       "      <th>coat_lite_tiny_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015670</td>\n",
       "      <td>IP_1235828</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>0.016618</td>\n",
       "      <td>0.006317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015845</td>\n",
       "      <td>IP_8170065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705232</td>\n",
       "      <td>0.936068</td>\n",
       "      <td>0.934974</td>\n",
       "      <td>0.012015</td>\n",
       "      <td>0.057499</td>\n",
       "      <td>0.020128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015864</td>\n",
       "      <td>IP_6724798</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.000935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0015902</td>\n",
       "      <td>IP_4111386</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.009385</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.001194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0024200</td>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.015275</td>\n",
       "      <td>0.016641</td>\n",
       "      <td>0.000733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401054</th>\n",
       "      <td>ISIC_9999937</td>\n",
       "      <td>IP_1140263</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.117205</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.517441</td>\n",
       "      <td>0.048114</td>\n",
       "      <td>0.040109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401055</th>\n",
       "      <td>ISIC_9999951</td>\n",
       "      <td>IP_5678181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.046718</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.029780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401056</th>\n",
       "      <td>ISIC_9999960</td>\n",
       "      <td>IP_0076153</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401057</th>\n",
       "      <td>ISIC_9999964</td>\n",
       "      <td>IP_5231513</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.299635</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.002088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401058</th>\n",
       "      <td>ISIC_9999967</td>\n",
       "      <td>IP_6426047</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.001403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401059 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             isic_id  patient_id  target       lgb        cb       xgb  \\\n",
       "0       ISIC_0015670  IP_1235828       0  0.000327  0.003275  0.000411   \n",
       "1       ISIC_0015845  IP_8170065       0  0.705232  0.936068  0.934974   \n",
       "2       ISIC_0015864  IP_6724798       0  0.000188  0.004573  0.000351   \n",
       "3       ISIC_0015902  IP_4111386       0  0.000577  0.004582  0.001001   \n",
       "4       ISIC_0024200  IP_8313778       0  0.001121  0.006794  0.000599   \n",
       "...              ...         ...     ...       ...       ...       ...   \n",
       "401054  ISIC_9999937  IP_1140263       0  0.010734  0.117205  0.007470   \n",
       "401055  ISIC_9999951  IP_5678181       0  0.000452  0.004976  0.000193   \n",
       "401056  ISIC_9999960  IP_0076153       0  0.002193  0.024668  0.001353   \n",
       "401057  ISIC_9999964  IP_5231513       0  0.000357  0.002312  0.000327   \n",
       "401058  ISIC_9999967  IP_6426047       0  0.000376  0.003353  0.001111   \n",
       "\n",
       "           eva02  eva02_tiny_patch14_224  coat_lite_tiny_2  \n",
       "0       0.027064                0.016618          0.006317  \n",
       "1       0.012015                0.057499          0.020128  \n",
       "2       0.003760                0.003339          0.000935  \n",
       "3       0.009385                0.001219          0.001194  \n",
       "4       0.015275                0.016641          0.000733  \n",
       "...          ...                     ...               ...  \n",
       "401054  0.517441                0.048114          0.040109  \n",
       "401055  0.046718                0.001689          0.029780  \n",
       "401056  0.014100                0.001682          0.001176  \n",
       "401057  0.299635                0.001080          0.002088  \n",
       "401058  0.001107                0.000675          0.001403  \n",
       "\n",
       "[401059 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['lgb', 'xgb', 'cb', 'eva02', 'eva02_tiny_patch14_224', 'coat_lite_tiny_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, new_feats = generate_zscore_features(gbdt_data)\n",
    "train_cols += new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, new_feats = generate_aggregated_features(train_df, ['lgb', 'xgb', 'cb', 'eva02', 'eva02_tiny_patch14_224', 'coat_lite_tiny_2'])\n",
    "train_cols += new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in train_cols:\n",
    "    median = train_df[feature].median()\n",
    "    train_df[feature] = train_df[feature].fillna(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = train_df[train_cols]\n",
    "y2 = train_df[target_col]\n",
    "groups2 = train_df[group_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - LR: 0.1709\n",
      "\n",
      "Fold 2 - LR: 0.1709\n",
      "\n",
      "Fold 3 - LR: 0.1566\n",
      "\n",
      "Fold 4 - LR: 0.1578\n",
      "\n",
      "Fold 5 - LR: 0.1827\n",
      "\n",
      "Average Scores - LR: 0.1678 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train soft on the oof preds using the same folds\n",
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scores = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(sgkf.split(X2, y2, groups2)):\n",
    "    X_train, X_valid = X2.iloc[train_idx], X2.iloc[valid_idx]\n",
    "    y_train, y_valid = y2.iloc[train_idx], y2.iloc[valid_idx]\n",
    "\n",
    "    lr = LogisticRegression(random_state=SEED, max_iter=1000)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    preds = lr.predict_proba(X_valid)[:,1]\n",
    "    score = oof_pauc(y_valid, preds)\n",
    "\n",
    "    scores.append(score)\n",
    "    print(f'Fold {fold + 1} - LR: {score:.4f}\\n')\n",
    "\n",
    "print(f'Average Scores - LR: {np.mean(scores):.4f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPStacker(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPStacker, self).__init__()\n",
    "        \n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.backbone(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        y_preds = []\n",
    "        y_true = []\n",
    "        model.train()\n",
    "        for batch_X, batch_y in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs.squeeze(), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            y_preds.extend(outputs.detach().cpu().numpy())\n",
    "            y_true.extend(batch_y.detach().cpu().numpy())\n",
    "\n",
    "        # pauc score\n",
    "        pauc = oof_pauc(np.array(y_true), np.array(y_preds))\n",
    "        print(f'Epoch {epoch + 1} - PAUC: {pauc:.4f}')\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_preds = []\n",
    "            val_true = []\n",
    "            for val_X, val_y in train_loader:\n",
    "                outputs = model(val_X)\n",
    "                val_preds.extend(outputs.detach().cpu().numpy())\n",
    "                val_true.extend(val_y.detach().cpu().numpy())\n",
    "\n",
    "            val_pauc = oof_pauc(np.array(val_true), np.array(val_preds))\n",
    "            print(f'Validation PAUC: {val_pauc:.4f}')\n",
    "\n",
    "# Prediction function\n",
    "def predict(model, X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        return model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24274b624b54479843567d221c5a702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m     30\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m predict(model, X_val)\n",
      "Cell \u001b[0;32mIn[158], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch_X)\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), batch_y)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     14\u001b[0m y_preds\u001b[38;5;241m.\u001b[39mextend(outputs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "cv_scores = []\n",
    "oof_predictions = np.zeros(len(X))\n",
    "\n",
    "X2 = torch.tensor(X2.values, dtype=torch.float32)\n",
    "y2 = torch.tensor(y2.values, dtype=torch.float32)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X2, y2, groups2)):\n",
    "    print(f\"Fold {fold}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X2[train_idx], X2[val_idx]\n",
    "    y_train, y_val = y2[train_idx], y2[val_idx]\n",
    "    \n",
    "    # Create DataLoader\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = MLPStacker(input_dim=X2.shape[1])\n",
    "    criterion = nn.BCELoss()  # or nn.BCEWithLogitsLoss() for binary classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(model, train_loader, criterion, optimizer)\n",
    "    \n",
    "    # Validate\n",
    "    val_predictions = predict(model, X_val)\n",
    "\n",
    "    # Calculate partial AUC\n",
    "    cv_score = oof_pauc(y_val, val_predictions)\n",
    "\n",
    "    cv_scores.append(cv_score)\n",
    "\n",
    "    oof_predictions[val_idx] = val_predictions.cpu().numpy().flatten()\n",
    "\n",
    "    print(f\"Partial AUC FOLD{fold}: {cv_score:.4f}\")\n",
    "\n",
    "print(f\"Mean Partial AUC: {np.mean(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
